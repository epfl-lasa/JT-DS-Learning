This paper proposes a dynamical system (DS) that operates in joint
space and converges to a desired position in task space. In doing so,
the authors use a linear parameter varying system and use
dimensionality reduction to learn these parameters efficiently. I think
the paper is well written, experiments are well conducted and
explained, and the results are promising. Detailed comments and
suggestions are as listed below:

1. As mentioned by the authors, there are many reasons to plan in joint
space rather than task space. One of the important reasons to me seems
to be able to plan end-effector orientation, not just position.
Traditional movement primitives, for example DMPs, do not explicitly
encode planning in the SO(3) space of orientations. There is research
that addresses this question, for example [1], but they lose the
simplistic appeal of movement primitives. I think it would be a great
addition to this paper if the authors illustrate if their joint space
DS can be used to accomplish orientation sensitive tasks, and
generalize to end-effector orientations different that what was
demonstrated. 
[1] Ude, Aleš, et al. "Orientation in cartesian space dynamic movement
primitives." Robotics and Automation (ICRA), 2014 IEEE International
Conference on. IEEE, 2014.

2. In the introduction, the authors stress that jacobian psuedo inverse
can be computationally expensive. Is this really true for a 7-dof robot
arm? Can the authors provide some numbers where this would really be an
issue for a robot controlled at 1000Hz? I find the argument that
jacobian inverse does not work for singularities and needs a set of
heuristics to be more compelling. Maybe the authors should rewrite the
introduction to stress more on this issue?
3. In Section II, ccriterion I, the authors talk about a positive
symmetric matrix P. I do not see it in the equations above. Is this a
weighing matrix?
4. In criterion II, the error is defined with respect to the velocity
error, rather than a position or a combination of both. This means that
the motion can be different from the demonstrated motion. I understand
that this is important to keep the later optimization convex, but is
there any disadvantage to using velocity error rather than position
error?
5. I do not completely understand the significance of A(q). From Figure
3, it seems like A(q) helps resolve redundancy, while achieving the
task space goal. Do the authors have a mathematical (in constrast to
intuitive) explanation for this? Does A(q) somehow relate to the
null-space of the jacobian?
6. In Section III, "One can intuitively understand the control law as
follows: (H(q)-x^*) denotes the position error w.r.t. the task target
and by multiplying that error by the transposed Jacobian J^T(q), the
error is projected into joint space (similar to Jacobian transpose
control)". I find this explanation misleading as jacobian multiplied to
position error does not project the error into joint space. Jacobian
transforms velocities, not positions. Maybe the law can be seen more as
a first order approximation of the error in task space. In any case, I
would either clarify this statement more or take it out of the
manuscript all together. It seems like the DS is just a PD law that
provably converges to a fixed attractor in task space.
7. About figure 2 again, the position error in task and joint space are
not simply multiplied by a Jacobian. Although, task space error can be
first-order approximated using a Jacobian multiplication with joint
space error. What does the right figure in Fig 2 exactly represent?
8. In Section IV, the authors say that they use EM to determine the
parameters of the GMM in Eq 6. Can they elaborate a little on this?
What is the expectation taken over and what likelihood is maximized?
9. The learned dimensionality reduction and parameters seem task
dependant. I wonder if the authors have any idea on how to generalize
this across tasks.
10. The experiments have the same task-space goal as the
demonstrations. Can the authors include experiments that have goals
different from demonstrated, especially in orientation?
11. In similar light, maybe authors could present online adaptation of
A(q) to generalize to situations different than demonstrated, for
example a slightly moved obstacle?
12. In table II, instead of the tracking error, maybe the more useful
error to see would be the error with respect to the plan or
demonstation. One would assume that the proposed approach would be
worse at it than SEDS+IK because the minimized error is with respect to
the velocity and goal, not the position of the movement.

Overall, I think this is an interesting, well written paper. I think
adding experiments with different goal - position and orientation will
help the paper, as well as an analysis of tracking error with respect
to a plan or demonstation.
